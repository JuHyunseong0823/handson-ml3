{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzf7951163RQ"
      },
      "source": [
        "**Support Vector Machines**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XStqhbqu63RR"
      },
      "source": [
        "_This notebook contains all the sample code and solutions to the exercises in chapter 5._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U634MZRa63RS"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml3/blob/main/05_support_vector_machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml3/blob/main/05_support_vector_machines.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "tOnrpG1w63RS"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oqXGrml63RS"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NDKo1pC63RS"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXHg8qCz63RT"
      },
      "source": [
        "It also requires Scikit-Learn ≥ 1.0.1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYQF7QBg63RT"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwEPMxGA63RT"
      },
      "source": [
        "As we did in previous chapters, let's define the default font sizes to make the figures prettier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tYHfH9f63RT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=14)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWCO-vx863RU"
      },
      "source": [
        "And let's create the `images/svm` folder (if it doesn't already exist), and define the `save_fig()` function which is used through this notebook to save the figures in high-res for the book:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDYF6EPe63RU"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "IMAGES_PATH = Path() / \"images\" / \"svm\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrOZ8L2O63RU"
      },
      "source": [
        "# Linear SVM Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHdUlNMa63RU"
      },
      "source": [
        "The book starts with a few figures, before the first code example, so the next three cells generate and save these figures. You can skip them if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyKY3SkJ63RU"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–1\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = iris.target\n",
        "\n",
        "setosa_or_versicolor = (y == 0) | (y == 1)\n",
        "X = X[setosa_or_versicolor]\n",
        "y = y[setosa_or_versicolor]\n",
        "\n",
        "# SVM Classifier model\n",
        "svm_clf = SVC(kernel=\"linear\", C=1e100)\n",
        "svm_clf.fit(X, y)\n",
        "\n",
        "# Bad models\n",
        "x0 = np.linspace(0, 5.5, 200)\n",
        "pred_1 = 5 * x0 - 20\n",
        "pred_2 = x0 - 1.8\n",
        "pred_3 = 0.1 * x0 + 0.5\n",
        "\n",
        "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
        "    w = svm_clf.coef_[0]\n",
        "    b = svm_clf.intercept_[0]\n",
        "\n",
        "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
        "    # => x1 = -w0/w1 * x0 - b/w1\n",
        "    x0 = np.linspace(xmin, xmax, 200)\n",
        "    decision_boundary = -w[0] / w[1] * x0 - b / w[1]\n",
        "\n",
        "    margin = 1/w[1]\n",
        "    gutter_up = decision_boundary + margin\n",
        "    gutter_down = decision_boundary - margin\n",
        "    svs = svm_clf.support_vectors_\n",
        "\n",
        "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2, zorder=-2)\n",
        "    plt.plot(x0, gutter_up, \"k--\", linewidth=2, zorder=-2)\n",
        "    plt.plot(x0, gutter_down, \"k--\", linewidth=2, zorder=-2)\n",
        "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#AAA',\n",
        "                zorder=-1)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.7), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(x0, pred_1, \"g--\", linewidth=2)\n",
        "plt.plot(x0, pred_2, \"m-\", linewidth=2)\n",
        "plt.plot(x0, pred_3, \"r-\", linewidth=2)\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.gca().set_aspect(\"equal\")\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_svc_decision_boundary(svm_clf, 0, 5.5)\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\")\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.gca().set_aspect(\"equal\")\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"large_margin_classification_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMX7m6a663RV"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–2\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "Xs = np.array([[1, 50], [5, 20], [3, 80], [5, 60]]).astype(np.float64)\n",
        "ys = np.array([0, 0, 1, 1])\n",
        "svm_clf = SVC(kernel=\"linear\", C=100).fit(Xs, ys)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(Xs)\n",
        "svm_clf_scaled = SVC(kernel=\"linear\", C=100).fit(X_scaled, ys)\n",
        "\n",
        "plt.figure(figsize=(9, 2.7))\n",
        "plt.subplot(121)\n",
        "plt.plot(Xs[:, 0][ys==1], Xs[:, 1][ys==1], \"bo\")\n",
        "plt.plot(Xs[:, 0][ys==0], Xs[:, 1][ys==0], \"ms\")\n",
        "plot_svc_decision_boundary(svm_clf, 0, 6)\n",
        "plt.xlabel(\"$x_0$\")\n",
        "plt.ylabel(\"$x_1$    \", rotation=0)\n",
        "plt.title(\"Unscaled\")\n",
        "plt.axis([0, 6, 0, 90])\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(X_scaled[:, 0][ys==1], X_scaled[:, 1][ys==1], \"bo\")\n",
        "plt.plot(X_scaled[:, 0][ys==0], X_scaled[:, 1][ys==0], \"ms\")\n",
        "plot_svc_decision_boundary(svm_clf_scaled, -2, 2)\n",
        "plt.xlabel(\"$x'_0$\")\n",
        "plt.ylabel(\"$x'_1$  \", rotation=0)\n",
        "plt.title(\"Scaled\")\n",
        "plt.axis([-2, 2, -2, 2])\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"sensitivity_to_feature_scales_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTjejYYf63RV"
      },
      "source": [
        "## Soft Margin Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJjxxVXN63RV"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–3\n",
        "\n",
        "X_outliers = np.array([[3.4, 1.3], [3.2, 0.8]])\n",
        "y_outliers = np.array([0, 0])\n",
        "Xo1 = np.concatenate([X, X_outliers[:1]], axis=0)\n",
        "yo1 = np.concatenate([y, y_outliers[:1]], axis=0)\n",
        "Xo2 = np.concatenate([X, X_outliers[1:]], axis=0)\n",
        "yo2 = np.concatenate([y, y_outliers[1:]], axis=0)\n",
        "\n",
        "svm_clf2 = SVC(kernel=\"linear\", C=10**9)\n",
        "svm_clf2.fit(Xo2, yo2)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.7), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(Xo1[:, 0][yo1==1], Xo1[:, 1][yo1==1], \"bs\")\n",
        "plt.plot(Xo1[:, 0][yo1==0], Xo1[:, 1][yo1==0], \"yo\")\n",
        "plt.text(0.3, 1.0, \"Impossible!\", color=\"red\", fontsize=18)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.annotate(\n",
        "    \"Outlier\",\n",
        "    xy=(X_outliers[0][0], X_outliers[0][1]),\n",
        "    xytext=(2.5, 1.7),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        ")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(Xo2[:, 0][yo2==1], Xo2[:, 1][yo2==1], \"bs\")\n",
        "plt.plot(Xo2[:, 0][yo2==0], Xo2[:, 1][yo2==0], \"yo\")\n",
        "plot_svc_decision_boundary(svm_clf2, 0, 5.5)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.annotate(\n",
        "    \"Outlier\",\n",
        "    xy=(X_outliers[1][0], X_outliers[1][1]),\n",
        "    xytext=(3.2, 0.08),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        ")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"sensitivity_to_outliers_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9eZdoG363RW"
      },
      "source": [
        "Note: the default value for the `dual` hyperparameter of the `LinearSVC` and `LinearSVR` estimators will change from `True` to `\"auto\"` in Scikit-Learn 1.4, so I set `dual=True` throughout this notebook to ensure the output of this notebook remains unchanged."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfLFoCvm63RW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "iris = load_iris(as_frame=True)\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = (iris.target == 2)  # Iris virginica\n",
        "\n",
        "svm_clf = make_pipeline(StandardScaler(),\n",
        "                        LinearSVC(C=1, dual=True, random_state=42))\n",
        "svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H4mhzNB63RW"
      },
      "outputs": [],
      "source": [
        "X_new = [[5.5, 1.7], [5.0, 1.5]]\n",
        "svm_clf.predict(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhJOYQJ263RW"
      },
      "outputs": [],
      "source": [
        "svm_clf.decision_function(X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sOl3_Rs63RW"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–4\n",
        "\n",
        "scaler = StandardScaler()\n",
        "svm_clf1 = LinearSVC(C=1, max_iter=10_000, dual=True, random_state=42)\n",
        "svm_clf2 = LinearSVC(C=100, max_iter=10_000, dual=True, random_state=42)\n",
        "\n",
        "scaled_svm_clf1 = make_pipeline(scaler, svm_clf1)\n",
        "scaled_svm_clf2 = make_pipeline(scaler, svm_clf2)\n",
        "\n",
        "scaled_svm_clf1.fit(X, y)\n",
        "scaled_svm_clf2.fit(X, y)\n",
        "\n",
        "# Convert to unscaled parameters\n",
        "b1 = svm_clf1.decision_function([-scaler.mean_ / scaler.scale_])\n",
        "b2 = svm_clf2.decision_function([-scaler.mean_ / scaler.scale_])\n",
        "w1 = svm_clf1.coef_[0] / scaler.scale_\n",
        "w2 = svm_clf2.coef_[0] / scaler.scale_\n",
        "svm_clf1.intercept_ = np.array([b1])\n",
        "svm_clf2.intercept_ = np.array([b2])\n",
        "svm_clf1.coef_ = np.array([w1])\n",
        "svm_clf2.coef_ = np.array([w2])\n",
        "\n",
        "# Find support vectors (LinearSVC does not do this automatically)\n",
        "t = y * 2 - 1\n",
        "support_vectors_idx1 = (t * (X.dot(w1) + b1) < 1).ravel()\n",
        "support_vectors_idx2 = (t * (X.dot(w2) + b2) < 1).ravel()\n",
        "svm_clf1.support_vectors_ = X[support_vectors_idx1]\n",
        "svm_clf2.support_vectors_ = X[support_vectors_idx2]\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 2.7), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\", label=\"Iris virginica\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\", label=\"Iris versicolor\")\n",
        "plot_svc_decision_boundary(svm_clf1, 4, 5.9)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.title(f\"$C = {svm_clf1.C}$\")\n",
        "plt.axis([4, 5.9, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
        "plot_svc_decision_boundary(svm_clf2, 4, 5.99)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.title(f\"$C = {svm_clf2.C}$\")\n",
        "plt.axis([4, 5.9, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "save_fig(\"regularization_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJDnT8I863RX"
      },
      "source": [
        "# Nonlinear SVM Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xliyYpci63RX"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–5\n",
        "\n",
        "X1D = np.linspace(-4, 4, 9).reshape(-1, 1)\n",
        "X2D = np.c_[X1D, X1D**2]\n",
        "y = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
        "\n",
        "plt.figure(figsize=(10, 3))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.plot(X1D[:, 0][y==0], np.zeros(4), \"bs\")\n",
        "plt.plot(X1D[:, 0][y==1], np.zeros(5), \"g^\")\n",
        "plt.gca().get_yaxis().set_ticks([])\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.axis([-4.5, 4.5, -0.2, 0.2])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.plot(X2D[:, 0][y==0], X2D[:, 1][y==0], \"bs\")\n",
        "plt.plot(X2D[:, 0][y==1], X2D[:, 1][y==1], \"g^\")\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"$x_2$  \", rotation=0)\n",
        "plt.gca().get_yaxis().set_ticks([0, 4, 8, 12, 16])\n",
        "plt.plot([-4.5, 4.5], [6.5, 6.5], \"r--\", linewidth=3)\n",
        "plt.axis([-4.5, 4.5, -1, 17])\n",
        "\n",
        "plt.subplots_adjust(right=1)\n",
        "\n",
        "save_fig(\"higher_dimensions_plot\", tight_layout=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRnlM0mW63RX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X, y = make_moons(n_samples=100, noise=0.15, random_state=42)\n",
        "\n",
        "polynomial_svm_clf = make_pipeline(\n",
        "    PolynomialFeatures(degree=3),\n",
        "    StandardScaler(),\n",
        "    LinearSVC(C=10, max_iter=10_000, dual=True, random_state=42)\n",
        ")\n",
        "polynomial_svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PTWTx0g63RX"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–6\n",
        "\n",
        "def plot_dataset(X, y, axes):\n",
        "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bs\")\n",
        "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
        "    plt.axis(axes)\n",
        "    plt.grid(True)\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    plt.ylabel(\"$x_2$\", rotation=0)\n",
        "\n",
        "def plot_predictions(clf, axes):\n",
        "    x0s = np.linspace(axes[0], axes[1], 100)\n",
        "    x1s = np.linspace(axes[2], axes[3], 100)\n",
        "    x0, x1 = np.meshgrid(x0s, x1s)\n",
        "    X = np.c_[x0.ravel(), x1.ravel()]\n",
        "    y_pred = clf.predict(X).reshape(x0.shape)\n",
        "    y_decision = clf.decision_function(X).reshape(x0.shape)\n",
        "    plt.contourf(x0, x1, y_pred, cmap=plt.cm.brg, alpha=0.2)\n",
        "    plt.contourf(x0, x1, y_decision, cmap=plt.cm.brg, alpha=0.1)\n",
        "\n",
        "plot_predictions(polynomial_svm_clf, [-1.5, 2.5, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.5, -1, 1.5])\n",
        "\n",
        "save_fig(\"moons_polynomial_svc_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmqPfm5m63RX"
      },
      "source": [
        "## Polynomial Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vT1h-CVo63RX"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "poly_kernel_svm_clf = make_pipeline(StandardScaler(),\n",
        "                                    SVC(kernel=\"poly\", degree=3, coef0=1, C=5))\n",
        "poly_kernel_svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T5rypAn63RX"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–7\n",
        "\n",
        "poly100_kernel_svm_clf = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    SVC(kernel=\"poly\", degree=10, coef0=100, C=5)\n",
        "    # LinearSVC(C=1000)\n",
        ")\n",
        "poly100_kernel_svm_clf.fit(X, y)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10.5, 4), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plot_predictions(poly_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])\n",
        "plt.title(\"degree=3, coef0=1, C=5\")\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_predictions(poly100_kernel_svm_clf, [-1.5, 2.45, -1, 1.5])\n",
        "plot_dataset(X, y, [-1.5, 2.4, -1, 1.5])\n",
        "plt.title(\"degree=10, coef0=100, C=5\")\n",
        "plt.ylabel(\"\")\n",
        "\n",
        "save_fig(\"moons_kernelized_polynomial_svc_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPGrj4Qk63RX"
      },
      "source": [
        "## Similarity Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3f9lpe_Q63RX"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–8\n",
        "\n",
        "def gaussian_rbf(x, landmark, gamma):\n",
        "    return np.exp(-gamma * np.linalg.norm(x - landmark, axis=1)**2)\n",
        "\n",
        "gamma = 0.3\n",
        "\n",
        "x1s = np.linspace(-4.5, 4.5, 200).reshape(-1, 1)\n",
        "x2s = gaussian_rbf(x1s, -2, gamma)\n",
        "x3s = gaussian_rbf(x1s, 1, gamma)\n",
        "\n",
        "XK = np.c_[gaussian_rbf(X1D, -2, gamma), gaussian_rbf(X1D, 1, gamma)]\n",
        "yk = np.array([0, 0, 1, 1, 1, 1, 1, 0, 0])\n",
        "\n",
        "plt.figure(figsize=(10.5, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.scatter(x=[-2, 1], y=[0, 0], s=150, alpha=0.5, c=\"red\")\n",
        "plt.plot(X1D[:, 0][yk==0], np.zeros(4), \"bs\")\n",
        "plt.plot(X1D[:, 0][yk==1], np.zeros(5), \"g^\")\n",
        "plt.plot(x1s, x2s, \"g--\")\n",
        "plt.plot(x1s, x3s, \"b:\")\n",
        "plt.gca().get_yaxis().set_ticks([0, 0.25, 0.5, 0.75, 1])\n",
        "plt.xlabel(\"$x_1$\")\n",
        "plt.ylabel(\"Similarity\")\n",
        "plt.annotate(\n",
        "    r'$\\mathbf{x}$',\n",
        "    xy=(X1D[3, 0], 0),\n",
        "    xytext=(-0.5, 0.20),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        "    fontsize=16,\n",
        ")\n",
        "plt.text(-2, 0.9, \"$x_2$\", ha=\"center\", fontsize=15)\n",
        "plt.text(1, 0.9, \"$x_3$\", ha=\"center\", fontsize=15)\n",
        "plt.axis([-4.5, 4.5, -0.1, 1.1])\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.grid(True)\n",
        "plt.axhline(y=0, color='k')\n",
        "plt.axvline(x=0, color='k')\n",
        "plt.plot(XK[:, 0][yk==0], XK[:, 1][yk==0], \"bs\")\n",
        "plt.plot(XK[:, 0][yk==1], XK[:, 1][yk==1], \"g^\")\n",
        "plt.xlabel(\"$x_2$\")\n",
        "plt.ylabel(\"$x_3$  \", rotation=0)\n",
        "plt.annotate(\n",
        "    r'$\\phi\\left(\\mathbf{x}\\right)$',\n",
        "    xy=(XK[3, 0], XK[3, 1]),\n",
        "    xytext=(0.65, 0.50),\n",
        "    ha=\"center\",\n",
        "    arrowprops=dict(facecolor='black', shrink=0.1),\n",
        "    fontsize=16,\n",
        ")\n",
        "plt.plot([-0.1, 1.1], [0.57, -0.1], \"r--\", linewidth=3)\n",
        "plt.axis([-0.1, 1.1, -0.1, 1.1])\n",
        "\n",
        "plt.subplots_adjust(right=1)\n",
        "\n",
        "save_fig(\"kernel_method_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkthhIdH63RY"
      },
      "source": [
        "## Gaussian RBF Kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDjOQI4a63RY"
      },
      "outputs": [],
      "source": [
        "rbf_kernel_svm_clf = make_pipeline(StandardScaler(),\n",
        "                                   SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
        "rbf_kernel_svm_clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lvNjhTyJ63RY"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–9\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "gamma1, gamma2 = 0.1, 1\n",
        "C1, C2 = 0.001, 1000\n",
        "hyperparams = (gamma1, C1), (gamma1, C2), (gamma2, C1), (gamma2, C2)\n",
        "\n",
        "svm_clfs = []\n",
        "for gamma, C in hyperparams:\n",
        "    rbf_kernel_svm_clf = make_pipeline(\n",
        "        StandardScaler(),\n",
        "        SVC(kernel=\"rbf\", gamma=gamma, C=C)\n",
        "    )\n",
        "    rbf_kernel_svm_clf.fit(X, y)\n",
        "    svm_clfs.append(rbf_kernel_svm_clf)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10.5, 7), sharex=True, sharey=True)\n",
        "\n",
        "for i, svm_clf in enumerate(svm_clfs):\n",
        "    plt.sca(axes[i // 2, i % 2])\n",
        "    plot_predictions(svm_clf, [-1.5, 2.45, -1, 1.5])\n",
        "    plot_dataset(X, y, [-1.5, 2.45, -1, 1.5])\n",
        "    gamma, C = hyperparams[i]\n",
        "    plt.title(f\"gamma={gamma}, C={C}\")\n",
        "    if i in (0, 1):\n",
        "        plt.xlabel(\"\")\n",
        "    if i in (1, 3):\n",
        "        plt.ylabel(\"\")\n",
        "\n",
        "save_fig(\"moons_rbf_svc_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9xuQ7Pe63RY"
      },
      "source": [
        "# SVM Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPKtJcs_63RY"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "# extra code – these 3 lines generate a simple linear dataset\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(50, 1)\n",
        "y = 4 + 3 * X[:, 0] + np.random.randn(50)\n",
        "\n",
        "svm_reg = make_pipeline(StandardScaler(),\n",
        "                        LinearSVR(epsilon=0.5, dual=True, random_state=42))\n",
        "svm_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZfruFED63RY"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–10\n",
        "\n",
        "def find_support_vectors(svm_reg, X, y):\n",
        "    y_pred = svm_reg.predict(X)\n",
        "    epsilon = svm_reg[-1].epsilon\n",
        "    off_margin = np.abs(y - y_pred) >= epsilon\n",
        "    return np.argwhere(off_margin)\n",
        "\n",
        "def plot_svm_regression(svm_reg, X, y, axes):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100).reshape(100, 1)\n",
        "    y_pred = svm_reg.predict(x1s)\n",
        "    epsilon = svm_reg[-1].epsilon\n",
        "    plt.plot(x1s, y_pred, \"k-\", linewidth=2, label=r\"$\\hat{y}$\", zorder=-2)\n",
        "    plt.plot(x1s, y_pred + epsilon, \"k--\", zorder=-2)\n",
        "    plt.plot(x1s, y_pred - epsilon, \"k--\", zorder=-2)\n",
        "    plt.scatter(X[svm_reg._support], y[svm_reg._support], s=180,\n",
        "                facecolors='#AAA', zorder=-1)\n",
        "    plt.plot(X, y, \"bo\")\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.axis(axes)\n",
        "\n",
        "svm_reg2 = make_pipeline(StandardScaler(),\n",
        "                         LinearSVR(epsilon=1.2, dual=True, random_state=42))\n",
        "svm_reg2.fit(X, y)\n",
        "\n",
        "svm_reg._support = find_support_vectors(svm_reg, X, y)\n",
        "svm_reg2._support = find_support_vectors(svm_reg2, X, y)\n",
        "\n",
        "eps_x1 = 1\n",
        "eps_y_pred = svm_reg2.predict([[eps_x1]])\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_svm_regression(svm_reg, X, y, [0, 2, 3, 11])\n",
        "plt.title(f\"epsilon={svm_reg[-1].epsilon}\")\n",
        "plt.ylabel(\"$y$\", rotation=0)\n",
        "plt.grid()\n",
        "plt.sca(axes[1])\n",
        "plot_svm_regression(svm_reg2, X, y, [0, 2, 3, 11])\n",
        "plt.title(f\"epsilon={svm_reg2[-1].epsilon}\")\n",
        "plt.annotate(\n",
        "        '', xy=(eps_x1, eps_y_pred), xycoords='data',\n",
        "        xytext=(eps_x1, eps_y_pred - svm_reg2[-1].epsilon),\n",
        "        textcoords='data', arrowprops={'arrowstyle': '<->', 'linewidth': 1.5}\n",
        "    )\n",
        "plt.text(0.90, 5.4, r\"$\\epsilon$\", fontsize=16)\n",
        "plt.grid()\n",
        "save_fig(\"svm_regression_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYtp_SM963RY"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "# extra code – these 3 lines generate a simple quadratic dataset\n",
        "np.random.seed(42)\n",
        "X = 2 * np.random.rand(50, 1) - 1\n",
        "y = 0.2 + 0.1 * X[:, 0] + 0.5 * X[:, 0] ** 2 + np.random.randn(50) / 10\n",
        "\n",
        "svm_poly_reg = make_pipeline(StandardScaler(),\n",
        "                             SVR(kernel=\"poly\", degree=2, C=0.1, epsilon=0.1))\n",
        "svm_poly_reg.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDuqXx8a63RY"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–11\n",
        "\n",
        "svm_poly_reg2 = make_pipeline(StandardScaler(),\n",
        "                             SVR(kernel=\"poly\", degree=2, C=100))\n",
        "svm_poly_reg2.fit(X, y)\n",
        "\n",
        "svm_poly_reg._support = find_support_vectors(svm_poly_reg, X, y)\n",
        "svm_poly_reg2._support = find_support_vectors(svm_poly_reg2, X, y)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(9, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_svm_regression(svm_poly_reg, X, y, [-1, 1, 0, 1])\n",
        "plt.title(f\"degree={svm_poly_reg[-1].degree}, \"\n",
        "          f\"C={svm_poly_reg[-1].C}, \"\n",
        "          f\"epsilon={svm_poly_reg[-1].epsilon}\")\n",
        "plt.ylabel(\"$y$\", rotation=0)\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_svm_regression(svm_poly_reg2, X, y, [-1, 1, 0, 1])\n",
        "plt.title(f\"degree={svm_poly_reg2[-1].degree}, \"\n",
        "          f\"C={svm_poly_reg2[-1].C}, \"\n",
        "          f\"epsilon={svm_poly_reg2[-1].epsilon}\")\n",
        "plt.grid()\n",
        "save_fig(\"svm_with_polynomial_kernel_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyztuUrI63RZ"
      },
      "source": [
        "# Under the hood"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBqm8-IV63RZ"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–12\n",
        "\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_2D_decision_function(w, b, ylabel=True, x1_lim=[-3, 3]):\n",
        "    x1 = np.linspace(x1_lim[0], x1_lim[1], 200)\n",
        "    y = w * x1 + b\n",
        "    half_margin = 1 / w\n",
        "\n",
        "    plt.plot(x1, y, \"b-\", linewidth=2, label=r\"$s = w_1 x_1$\")\n",
        "    plt.axhline(y=0, color='k', linewidth=1)\n",
        "    plt.axvline(x=0, color='k', linewidth=1)\n",
        "    rect = patches.Rectangle((-half_margin, -2), 2 * half_margin, 4,\n",
        "                             edgecolor='none', facecolor='gray', alpha=0.2)\n",
        "    plt.gca().add_patch(rect)\n",
        "    plt.plot([-3, 3], [1, 1], \"k--\", linewidth=1)\n",
        "    plt.plot([-3, 3], [-1, -1], \"k--\", linewidth=1)\n",
        "    plt.plot(half_margin, 1, \"k.\")\n",
        "    plt.plot(-half_margin, -1, \"k.\")\n",
        "    plt.axis(x1_lim + [-2, 2])\n",
        "    plt.xlabel(\"$x_1$\")\n",
        "    if ylabel:\n",
        "        plt.ylabel(\"$s$\", rotation=0, labelpad=5)\n",
        "        plt.legend()\n",
        "        plt.text(1.02, -1.6, \"Margin\", ha=\"left\", va=\"center\", color=\"k\")\n",
        "\n",
        "    plt.annotate(\n",
        "        '', xy=(-half_margin, -1.6), xytext=(half_margin, -1.6),\n",
        "        arrowprops={'ec': 'k', 'arrowstyle': '<->', 'linewidth': 1.5}\n",
        "    )\n",
        "    plt.title(f\"$w_1 = {w}$\")\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(9, 3.2), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_2D_decision_function(1, 0)\n",
        "plt.grid()\n",
        "plt.sca(axes[1])\n",
        "plot_2D_decision_function(0.5, 0, ylabel=False)\n",
        "plt.grid()\n",
        "save_fig(\"small_w_large_margin_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs6Og4fx63RZ"
      },
      "outputs": [],
      "source": [
        "# extra code – this cell generates and saves Figure 5–13\n",
        "\n",
        "s = np.linspace(-2.5, 2.5, 200)\n",
        "hinge_pos = np.where(1 - s < 0, 0, 1 - s)  # max(0, 1 - s)\n",
        "hinge_neg = np.where(1 + s < 0, 0, 1 + s)  # max(0, 1 + s)\n",
        "\n",
        "titles = (r\"Hinge loss = $max(0, 1 - s\\,t)$\", \"Squared Hinge loss\")\n",
        "\n",
        "fix, axs = plt.subplots(1, 2, sharey=True, figsize=(8.2, 3))\n",
        "\n",
        "for ax, loss_pos, loss_neg, title in zip(\n",
        "        axs, (hinge_pos, hinge_pos ** 2), (hinge_neg, hinge_neg ** 2), titles):\n",
        "    ax.plot(s, loss_pos, \"g-\", linewidth=2, zorder=10, label=\"$t=1$\")\n",
        "    ax.plot(s, loss_neg, \"r--\", linewidth=2, zorder=10, label=\"$t=-1$\")\n",
        "    ax.grid(True)\n",
        "    ax.axhline(y=0, color='k')\n",
        "    ax.axvline(x=0, color='k')\n",
        "    ax.set_xlabel(r\"$s = \\mathbf{w}^\\intercal \\mathbf{x} + b$\")\n",
        "    ax.axis([-2.5, 2.5, -0.5, 2.5])\n",
        "    ax.legend(loc=\"center right\")\n",
        "    ax.set_title(title)\n",
        "    ax.set_yticks(np.arange(0, 2.5, 1))\n",
        "    ax.set_aspect(\"equal\")\n",
        "\n",
        "save_fig(\"hinge_plot\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNSo982u63RZ"
      },
      "source": [
        "# Extra Material"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3meLB_7b63RZ"
      },
      "source": [
        "## Linear SVM classifier implementation using Batch Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fjQLLN_63RZ"
      },
      "outputs": [],
      "source": [
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = (iris.target == 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Xfnrrg_63RZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class MyLinearSVC(BaseEstimator):\n",
        "    def __init__(self, C=1, eta0=1, eta_d=10000, n_epochs=1000,\n",
        "                 random_state=None):\n",
        "        self.C = C\n",
        "        self.eta0 = eta0\n",
        "        self.n_epochs = n_epochs\n",
        "        self.random_state = random_state\n",
        "        self.eta_d = eta_d\n",
        "\n",
        "    def eta(self, epoch):\n",
        "        return self.eta0 / (epoch + self.eta_d)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Random initialization\n",
        "        if self.random_state:\n",
        "            np.random.seed(self.random_state)\n",
        "        w = np.random.randn(X.shape[1], 1)  # n feature weights\n",
        "        b = 0\n",
        "\n",
        "        t = np.array(y, dtype=np.float64).reshape(-1, 1) * 2 - 1\n",
        "        X_t = X * t\n",
        "        self.Js = []\n",
        "\n",
        "        # Training\n",
        "        for epoch in range(self.n_epochs):\n",
        "            support_vectors_idx = (X_t.dot(w) + t * b < 1).ravel()\n",
        "            X_t_sv = X_t[support_vectors_idx]\n",
        "            t_sv = t[support_vectors_idx]\n",
        "\n",
        "            J = 1/2 * (w * w).sum() + self.C * ((1 - X_t_sv.dot(w)).sum() - b * t_sv.sum())\n",
        "            self.Js.append(J)\n",
        "\n",
        "            w_gradient_vector = w - self.C * X_t_sv.sum(axis=0).reshape(-1, 1)\n",
        "            b_derivative = -self.C * t_sv.sum()\n",
        "\n",
        "            w = w - self.eta(epoch) * w_gradient_vector\n",
        "            b = b - self.eta(epoch) * b_derivative\n",
        "\n",
        "\n",
        "        self.intercept_ = np.array([b])\n",
        "        self.coef_ = np.array([w])\n",
        "        support_vectors_idx = (X_t.dot(w) + t * b < 1).ravel()\n",
        "        self.support_vectors_ = X[support_vectors_idx]\n",
        "        return self\n",
        "\n",
        "    def decision_function(self, X):\n",
        "        return X.dot(self.coef_[0]) + self.intercept_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.decision_function(X) >= 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xq1cYSjk63RZ"
      },
      "outputs": [],
      "source": [
        "C = 2\n",
        "svm_clf = MyLinearSVC(C=C, eta0 = 10, eta_d = 1000, n_epochs=60000,\n",
        "                      random_state=2)\n",
        "svm_clf.fit(X, y)\n",
        "svm_clf.predict(np.array([[5, 2], [4, 1]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t9WHWay63RZ"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(svm_clf.n_epochs), svm_clf.Js)\n",
        "plt.axis([0, svm_clf.n_epochs, 0, 100])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iT-zZPFD63RZ"
      },
      "outputs": [],
      "source": [
        "print(svm_clf.intercept_, svm_clf.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgfLl3s363RZ"
      },
      "outputs": [],
      "source": [
        "svm_clf2 = SVC(kernel=\"linear\", C=C)\n",
        "svm_clf2.fit(X, y.ravel())\n",
        "print(svm_clf2.intercept_, svm_clf2.coef_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAjiJ8VS63Ra"
      },
      "outputs": [],
      "source": [
        "yr = y.ravel()\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(11, 3.2), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], \"g^\", label=\"Iris virginica\")\n",
        "plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], \"bs\", label=\"Not Iris virginica\")\n",
        "plot_svc_decision_boundary(svm_clf, 4, 6)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.title(\"MyLinearSVC\")\n",
        "plt.axis([4, 6, 0.8, 2.8])\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.grid()\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], \"g^\")\n",
        "plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], \"bs\")\n",
        "plot_svc_decision_boundary(svm_clf2, 4, 6)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.title(\"SVC\")\n",
        "plt.axis([4, 6, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LxDyTvL763Ra"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(loss=\"hinge\", alpha=0.017, max_iter=1000, tol=1e-3,\n",
        "                        random_state=42)\n",
        "sgd_clf.fit(X, y)\n",
        "\n",
        "m = len(X)\n",
        "t = np.array(y).reshape(-1, 1) * 2 - 1  # -1 if y == 0, or +1 if y == 1\n",
        "X_b = np.c_[np.ones((m, 1)), X]  # Add bias input x0=1\n",
        "X_b_t = X_b * t\n",
        "sgd_theta = np.r_[sgd_clf.intercept_[0], sgd_clf.coef_[0]]\n",
        "print(sgd_theta)\n",
        "support_vectors_idx = (X_b_t.dot(sgd_theta) < 1).ravel()\n",
        "sgd_clf.support_vectors_ = X[support_vectors_idx]\n",
        "sgd_clf.C = C\n",
        "\n",
        "plt.figure(figsize=(5.5, 3.2))\n",
        "plt.plot(X[:, 0][yr==1], X[:, 1][yr==1], \"g^\")\n",
        "plt.plot(X[:, 0][yr==0], X[:, 1][yr==0], \"bs\")\n",
        "plot_svc_decision_boundary(sgd_clf, 4, 6)\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.title(\"SGDClassifier\")\n",
        "plt.axis([4, 6, 0.8, 2.8])\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9"
      ],
      "metadata": {
        "id": "sDhgDG-3HtnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.zeros((100, 2))\n",
        "X[:50, 0] = 2 * np.random.randn(50, ) + 3\n",
        "X[:50, 1] = 3 * np.random.randn(50, ) + 4\n",
        "X[50:, 0] = 2 * np.random.randn(50, ) - 2\n",
        "X[50:, 1] = 3 * np.random.randn(50, ) - 3\n",
        "y = np.array([0] * 50 + [1] * 50)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "17aqRWXeHuPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_svm = make_pipeline(StandardScaler(),\n",
        "                        LinearSVC(C=1, random_state=42))\n",
        "lin_svm.fit(X, y)\n",
        "lin_svm.predict(X)\n",
        "\n",
        "x0 = np.linspace(-6, 6, 100)\n",
        "x1 = np.linspace(-10, 10, 100)\n",
        "x0, x1 = np.meshgrid(x0, x1)\n",
        "\n",
        "x = np.hstack((x0.reshape(-1, 1), x1.reshape(-1, 1)))\n",
        "y_pred = lin_svm.predict(x)\n",
        "\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.contour(x0, x1, y_pred.reshape(100, 100), cmap=plt.cm.brg, alpha=0.2)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4gYzopgeIWkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "model2 = make_pipeline(StandardScaler(),\n",
        "                       SVC(kernel=\"linear\", C=1))\n",
        "model2.fit(X, y)\n",
        "\n",
        "model3 = make_pipeline(StandardScaler(),\n",
        "                       SGDClassifier())\n",
        "model3.fit(X, y)\n",
        "\n",
        "y2_pred = model2.predict(x)\n",
        "y3_pred = model3.predict(x)\n",
        "plt.contour(x0, x1, y_pred.reshape(100, 100), cmap=plt.cm.brg, alpha=0.2)\n",
        "plt.contour(x0, x1, y2_pred.reshape(100, 100), cmap=plt.cm.brg, alpha=0.2)\n",
        "plt.contour(x0, x1, y3_pred.reshape(100, 100), cmap='inferno', alpha=0.2)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BMxGFxB3KiHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10"
      ],
      "metadata": {
        "id": "kQQUophkLMmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_wine()\n",
        "X = data['data']\n",
        "y = data['target']\n",
        "X.shape, y.shape\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_tr = encoder.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y_tr, test_size=0.2)\n",
        "X_train.shape, Y_train.shape"
      ],
      "metadata": {
        "id": "mILDwRBrLM8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OFq-HL48Q75K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.utils.validation import check_is_fitted, check_array\n",
        "\n",
        "class OvASVM(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, label_num=3, **kwargs):\n",
        "        self.models = []\n",
        "        for _ in range(label_num):\n",
        "          self.models.append(SVC(**kwargs, probability=True))\n",
        "        self.label_num = label_num\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "      X = check_array(X)\n",
        "      self.n_features_ = X.shape[1]\n",
        "      assert y.shape[1] == self.label_num\n",
        "      for i in range(self.label_num):\n",
        "        y_i = y[:, i]\n",
        "        self.models[i].fit(X, y_i)\n",
        "      return self\n",
        "\n",
        "    def predict(self, X):\n",
        "      check_is_fitted(self)\n",
        "      X = check_array(X)\n",
        "      assert X.shape[1] == self.n_features_\n",
        "      y_pred = np.zeros((X.shape[0], self.label_num))\n",
        "      for i in range(self.label_num):\n",
        "        y_pred[:, i] = self.models[i].predict_proba(X)[:, 1]\n",
        "      return y_pred\n",
        "\n",
        "\n",
        "pipeline = make_pipeline(StandardScaler(),\n",
        "                         OvASVM(label_num=3, kernel=\"poly\", degree=3, coef0=1, C=5))\n",
        "pipeline.fit(X_train, Y_train)\n",
        "Y_pred = pipeline.predict(X_test)\n",
        "\n",
        "accuracy = Y_pred.argmax(axis=1) == Y_test.argmax(axis=1)\n",
        "accuracy.mean()\n"
      ],
      "metadata": {
        "id": "iG_iLcauMIix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11"
      ],
      "metadata": {
        "id": "wXwkx2kXRRv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "X.shape, y.shape\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "6z0wCJCJNS-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from scipy.stats import reciprocal, uniform\n",
        "\n",
        "svm_reg = Pipeline([('scaler', StandardScaler()),\n",
        "                    ('svr', SVR(kernel='poly'))])\n",
        "param_grid = [\n",
        "    {'svr__degree': range(1, 21),\n",
        "     'svr__C': reciprocal(0.01, 100),\n",
        "    'svr__epsilon': reciprocal(0.1, 10)}\n",
        "]\n",
        "grid_search = RandomizedSearchCV(svm_reg, param_grid, cv=3, scoring='neg_mean_squared_error', n_iter=20, verbose=4)\n",
        "search_result = grid_search.fit(X_train[:2000], Y_train[:2000])\n",
        "\n",
        "search_result.best_params_"
      ],
      "metadata": {
        "id": "hZw_xMgiRyJg",
        "outputId": "d4dea664-2634-4321-95fb-150fcaf1e012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
            "[CV 1/3] END svr__C=65.73829505684881, svr__degree=16, svr__epsilon=0.15849489395603464;, score=-7788286859658552320.000 total time=   0.2s\n",
            "[CV 2/3] END svr__C=65.73829505684881, svr__degree=16, svr__epsilon=0.15849489395603464;, score=-492068788597399683072.000 total time=   0.1s\n",
            "[CV 3/3] END svr__C=65.73829505684881, svr__degree=16, svr__epsilon=0.15849489395603464;, score=-223452963921.119 total time=   0.2s\n",
            "[CV 1/3] END svr__C=0.06643730463606294, svr__degree=10, svr__epsilon=8.145784874513655;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.06643730463606294, svr__degree=10, svr__epsilon=8.145784874513655;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.06643730463606294, svr__degree=10, svr__epsilon=8.145784874513655;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.9994005651554041, svr__degree=8, svr__epsilon=0.10230956879424292;, score=-456850.554 total time=   0.1s\n",
            "[CV 2/3] END svr__C=0.9994005651554041, svr__degree=8, svr__epsilon=0.10230956879424292;, score=-85092076.107 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.9994005651554041, svr__degree=8, svr__epsilon=0.10230956879424292;, score=-1964.705 total time=   0.0s\n",
            "[CV 1/3] END svr__C=70.01744107980268, svr__degree=6, svr__epsilon=2.022536185030452;, score=-18.054 total time=   0.0s\n",
            "[CV 2/3] END svr__C=70.01744107980268, svr__degree=6, svr__epsilon=2.022536185030452;, score=-49404.663 total time=   0.0s\n",
            "[CV 3/3] END svr__C=70.01744107980268, svr__degree=6, svr__epsilon=2.022536185030452;, score=-3.665 total time=   0.0s\n",
            "[CV 1/3] END svr__C=25.98161305398874, svr__degree=16, svr__epsilon=7.8940140028721695;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=25.98161305398874, svr__degree=16, svr__epsilon=7.8940140028721695;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=25.98161305398874, svr__degree=16, svr__epsilon=7.8940140028721695;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=1.1537461070284942, svr__degree=14, svr__epsilon=3.626571013655913;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=1.1537461070284942, svr__degree=14, svr__epsilon=3.626571013655913;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=1.1537461070284942, svr__degree=14, svr__epsilon=3.626571013655913;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=73.68625196849422, svr__degree=7, svr__epsilon=5.252844760142194;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=73.68625196849422, svr__degree=7, svr__epsilon=5.252844760142194;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=73.68625196849422, svr__degree=7, svr__epsilon=5.252844760142194;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=47.3233169677926, svr__degree=13, svr__epsilon=0.3004460466740457;, score=-80773413540975.438 total time=   0.1s\n",
            "[CV 2/3] END svr__C=47.3233169677926, svr__degree=13, svr__epsilon=0.3004460466740457;, score=-17327902346624916.000 total time=   0.1s\n",
            "[CV 3/3] END svr__C=47.3233169677926, svr__degree=13, svr__epsilon=0.3004460466740457;, score=-7078011.144 total time=   0.1s\n",
            "[CV 1/3] END svr__C=2.6537509445051235, svr__degree=5, svr__epsilon=8.329315465102587;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=2.6537509445051235, svr__degree=5, svr__epsilon=8.329315465102587;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=2.6537509445051235, svr__degree=5, svr__epsilon=8.329315465102587;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.15798924300819267, svr__degree=11, svr__epsilon=0.1552559844929366;, score=-7786974555.227 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.15798924300819267, svr__degree=11, svr__epsilon=0.1552559844929366;, score=-1151635076851.170 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.15798924300819267, svr__degree=11, svr__epsilon=0.1552559844929366;, score=-194611.264 total time=   0.0s\n",
            "[CV 1/3] END svr__C=14.98825648153785, svr__degree=14, svr__epsilon=4.419412591521953;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=14.98825648153785, svr__degree=14, svr__epsilon=4.419412591521953;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=14.98825648153785, svr__degree=14, svr__epsilon=4.419412591521953;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=45.34642611691995, svr__degree=14, svr__epsilon=7.663380646057194;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=45.34642611691995, svr__degree=14, svr__epsilon=7.663380646057194;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=45.34642611691995, svr__degree=14, svr__epsilon=7.663380646057194;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.14894930234378356, svr__degree=7, svr__epsilon=0.5864510647027523;, score=-12504.665 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.14894930234378356, svr__degree=7, svr__epsilon=0.5864510647027523;, score=-78448.459 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.14894930234378356, svr__degree=7, svr__epsilon=0.5864510647027523;, score=-12.186 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.5504377285280797, svr__degree=10, svr__epsilon=0.8372056055956704;, score=-48144073.498 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.5504377285280797, svr__degree=10, svr__epsilon=0.8372056055956704;, score=-14214653453.660 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.5504377285280797, svr__degree=10, svr__epsilon=0.8372056055956704;, score=-769.040 total time=   0.0s\n",
            "[CV 1/3] END svr__C=42.00265362247618, svr__degree=9, svr__epsilon=5.111749542531406;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=42.00265362247618, svr__degree=9, svr__epsilon=5.111749542531406;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=42.00265362247618, svr__degree=9, svr__epsilon=5.111749542531406;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.07709703971181252, svr__degree=14, svr__epsilon=7.892245441257127;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.07709703971181252, svr__degree=14, svr__epsilon=7.892245441257127;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.07709703971181252, svr__degree=14, svr__epsilon=7.892245441257127;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=4.594414749495135, svr__degree=8, svr__epsilon=0.5880265547497712;, score=-2357132.123 total time=   0.0s\n",
            "[CV 2/3] END svr__C=4.594414749495135, svr__degree=8, svr__epsilon=0.5880265547497712;, score=-42077008.116 total time=   0.1s\n",
            "[CV 3/3] END svr__C=4.594414749495135, svr__degree=8, svr__epsilon=0.5880265547497712;, score=-431.674 total time=   0.1s\n",
            "[CV 1/3] END svr__C=1.5815114806486443, svr__degree=17, svr__epsilon=3.791712711527015;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=1.5815114806486443, svr__degree=17, svr__epsilon=3.791712711527015;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=1.5815114806486443, svr__degree=17, svr__epsilon=3.791712711527015;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.04200805471589378, svr__degree=7, svr__epsilon=0.2172560772667051;, score=-11356.439 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.04200805471589378, svr__degree=7, svr__epsilon=0.2172560772667051;, score=-76.725 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.04200805471589378, svr__degree=7, svr__epsilon=0.2172560772667051;, score=-7.052 total time=   0.1s\n",
            "[CV 1/3] END svr__C=0.5152163121944564, svr__degree=7, svr__epsilon=1.395895635824093;, score=-975.564 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.5152163121944564, svr__degree=7, svr__epsilon=1.395895635824093;, score=-688312.523 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.5152163121944564, svr__degree=7, svr__epsilon=1.395895635824093;, score=-6.939 total time=   0.0s\n",
            "[CV 1/3] END svr__C=3.4149139117397733, svr__degree=10, svr__epsilon=0.10563993290313545;, score=-3242237979.842 total time=   0.2s\n",
            "[CV 2/3] END svr__C=3.4149139117397733, svr__degree=10, svr__epsilon=0.10563993290313545;, score=-699873187348.895 total time=   0.1s\n",
            "[CV 3/3] END svr__C=3.4149139117397733, svr__degree=10, svr__epsilon=0.10563993290313545;, score=-168282.566 total time=   0.2s\n",
            "[CV 1/3] END svr__C=0.2292651444001829, svr__degree=4, svr__epsilon=0.8262431931424324;, score=-1.382 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.2292651444001829, svr__degree=4, svr__epsilon=0.8262431931424324;, score=-23.860 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.2292651444001829, svr__degree=4, svr__epsilon=0.8262431931424324;, score=-1.106 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.03172013249250589, svr__degree=17, svr__epsilon=0.12209738103642744;, score=-217741860435461056.000 total time=   0.1s\n",
            "[CV 2/3] END svr__C=0.03172013249250589, svr__degree=17, svr__epsilon=0.12209738103642744;, score=-1369290599703256498176.000 total time=   0.1s\n",
            "[CV 3/3] END svr__C=0.03172013249250589, svr__degree=17, svr__epsilon=0.12209738103642744;, score=-409163490951.552 total time=   0.1s\n",
            "[CV 1/3] END svr__C=0.46165101397812736, svr__degree=9, svr__epsilon=3.510764020142686;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.46165101397812736, svr__degree=9, svr__epsilon=3.510764020142686;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.46165101397812736, svr__degree=9, svr__epsilon=3.510764020142686;, score=-1.628 total time=   0.0s\n",
            "[CV 1/3] END svr__C=0.09356316246772473, svr__degree=15, svr__epsilon=3.363087701856342;, score=-1.821 total time=   0.0s\n",
            "[CV 2/3] END svr__C=0.09356316246772473, svr__degree=15, svr__epsilon=3.363087701856342;, score=-1.748 total time=   0.0s\n",
            "[CV 3/3] END svr__C=0.09356316246772473, svr__degree=15, svr__epsilon=3.363087701856342;, score=-1.628 total time=   0.0s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kPnK_ou63Ra"
      },
      "source": [
        "# Exercise solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrE78iNt63Ra"
      },
      "source": [
        "## 1. to 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSEKimTF63Ra"
      },
      "source": [
        "1. The fundamental idea behind Support Vector Machines is to fit the widest possible \"street\" between the classes. In other words, the goal is to have the largest possible margin between the decision boundary that separates the two classes and the training instances. When performing soft margin classification, the SVM searches for a compromise between perfectly separating the two classes and having the widest possible street (i.e., a few instances may end up on the street). Another key idea is to use kernels when training on nonlinear datasets. SVMs can also be tweaked to perform linear and nonlinear regression, as well as novelty detection.\n",
        "2. After training an SVM, a _support vector_ is any instance located on the \"street\" (see the previous answer), including its border. The decision boundary is entirely determined by the support vectors. Any instance that is _not_ a support vector (i.e., is off the street) has no influence whatsoever; you could remove them, add more instances, or move them around, and as long as they stay off the street they won't affect the decision boundary. Computing the predictions with a kernelized SVM only involves the support vectors, not the whole training set.\n",
        "3. SVMs try to fit the largest possible \"street\" between the classes (see the first answer), so if the training set is not scaled, the SVM will tend to neglect small features (see Figure 5–2).\n",
        "4. You can use the `decision_function()` method to get confidence scores. These scores represent the distance between the instance and the decision boundary. However, they cannot be directly converted into an estimation of the class probability. If you set `probability=True` when creating an `SVC`, then at the end of training it will use 5-fold cross-validation to generate out-of-sample scores for the training samples, and it will train a `LogisticRegression` model to map these scores to estimated probabilities. The `predict_proba()` and `predict_log_proba()` methods will then be available.\n",
        "5. All three classes can be used for large-margin linear classification. The `SVC` class also supports the kernel trick, which makes it capable of handling nonlinear tasks. However, this comes at a cost: the `SVC` class does not scale well to datasets with many instances. It does scale well to a large number of features, though. The `LinearSVC` class implements an optimized algorithm for linear SVMs, while `SGDClassifier` uses Stochastic Gradient Descent. Depending on the dataset `LinearSVC` may be a bit faster than `SGDClassifier`, but not always, and `SGDClassifier` is more flexible, plus it supports incremental learning.\n",
        "6. If an SVM classifier trained with an RBF kernel underfits the training set, there might be too much regularization. To decrease it, you need to increase `gamma` or `C` (or both).\n",
        "7. A Regression SVM model tries to fit as many instances within a small margin around its predictions. If you add instances within this margin, the model will not be affected at all: it is said to be _ϵ-insensitive_.\n",
        "8. The kernel trick is mathematical technique that makes it possible to train a nonlinear SVM model. The resulting model is equivalent to mapping the inputs to another space using a nonlinear transformation, then training a linear SVM on the resulting high-dimensional inputs. The kernel trick gives the same result without having to transform the inputs at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txnRA87p63Ra"
      },
      "source": [
        "# 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dLEwwuW63Ra"
      },
      "source": [
        "_Exercise: Train a `LinearSVC` on a linearly separable dataset. Then train an `SVC` and a `SGDClassifier` on the same dataset. See if you can get them to produce roughly the same model._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFyWBCKo63Ra"
      },
      "source": [
        "Let's use the Iris dataset: the Iris Setosa and Iris Versicolor classes are linearly separable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP-1A0sL63Ra"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris(as_frame=True)\n",
        "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
        "y = iris.target\n",
        "\n",
        "setosa_or_versicolor = (y == 0) | (y == 1)\n",
        "X = X[setosa_or_versicolor]\n",
        "y = y[setosa_or_versicolor]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S05I1Aa63Ra"
      },
      "source": [
        "Now let's build and train 3 models:\n",
        "* Remember that `LinearSVC` uses `loss=\"squared_hinge\"` by default, so if we want all 3 models to produce similar results, we need to set `loss=\"hinge\"`.\n",
        "* Also, the `SVC` class uses an RBF kernel by default, so we need to set `kernel=\"linear\"` to get similar results as the other two models.\n",
        "* Lastly, the `SGDClassifier` class does not have a `C` hyperparameter, but it has another regularization hyperparameter called `alpha`, so we can tweak it to get similar results as the other two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FftWH7jI63Ra"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "C = 5\n",
        "alpha = 0.05\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "lin_clf = LinearSVC(loss=\"hinge\", C=C, dual=True, random_state=42).fit(X_scaled, y)\n",
        "svc_clf = SVC(kernel=\"linear\", C=C).fit(X_scaled, y)\n",
        "sgd_clf = SGDClassifier(alpha=alpha, random_state=42).fit(X_scaled, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYa6_Ixx63Ra"
      },
      "source": [
        "Let's plot the decision boundaries of these three models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yemQefYS63Ra",
        "outputId": "8ad10b43-e58b-427d-86d5-b6876044e584"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def compute_decision_boundary(model):\n",
        "    w = -model.coef_[0, 0] / model.coef_[0, 1]\n",
        "    b = -model.intercept_[0] / model.coef_[0, 1]\n",
        "    return scaler.inverse_transform([[-10, -10 * w + b], [10, 10 * w + b]])\n",
        "\n",
        "lin_line = compute_decision_boundary(lin_clf)\n",
        "svc_line = compute_decision_boundary(svc_clf)\n",
        "sgd_line = compute_decision_boundary(sgd_clf)\n",
        "\n",
        "# Plot all three decision boundaries\n",
        "plt.figure(figsize=(11, 4))\n",
        "plt.plot(lin_line[:, 0], lin_line[:, 1], \"k:\", label=\"LinearSVC\")\n",
        "plt.plot(svc_line[:, 0], svc_line[:, 1], \"b--\", linewidth=2, label=\"SVC\")\n",
        "plt.plot(sgd_line[:, 0], sgd_line[:, 1], \"r-\", label=\"SGDClassifier\")\n",
        "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\") # label=\"Iris versicolor\"\n",
        "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\") # label=\"Iris setosa\"\n",
        "plt.xlabel(\"Petal length\")\n",
        "plt.ylabel(\"Petal width\")\n",
        "plt.legend(loc=\"upper center\")\n",
        "plt.axis([0, 5.5, 0, 2])\n",
        "plt.grid()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En_bRNDm63Rb"
      },
      "source": [
        "Close enough!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkKwFMG263Rb"
      },
      "source": [
        "# 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHvPoEpQ63Rb"
      },
      "source": [
        "_Exercise: Train an SVM classifier on the Wine dataset, which you can load using `sklearn.datasets.load_wine()`. This dataset contains the chemical analysis of 178 wine samples produced by 3 different cultivators: the goal is to train a classification model capable of predicting the cultivator based on the wine's chemical analysis. Since SVM classifiers are binary classifiers, you will need to use one-versus-all to classify all 3 classes. What accuracy can you reach?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bRx-_JB63Rb"
      },
      "source": [
        "First, let's fetch the dataset, look at its description, then split it into a training set and a test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCrggQKF63Rb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "wine = load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsRI5mh663Rb",
        "outputId": "fb999345-0adc-428f-eb9a-5fd1a7505783"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".. _wine_dataset:\n",
            "\n",
            "Wine recognition dataset\n",
            "------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 178 (50 in each of three classes)\n",
            "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
            "    :Attribute Information:\n",
            " \t\t- Alcohol\n",
            " \t\t- Malic acid\n",
            " \t\t- Ash\n",
            "\t\t- Alcalinity of ash  \n",
            " \t\t- Magnesium\n",
            "\t\t- Total phenols\n",
            " \t\t- Flavanoids\n",
            " \t\t- Nonflavanoid phenols\n",
            " \t\t- Proanthocyanins\n",
            "\t\t- Color intensity\n",
            " \t\t- Hue\n",
            " \t\t- OD280/OD315 of diluted wines\n",
            " \t\t- Proline\n",
            "\n",
            "    - class:\n",
            "            - class_0\n",
            "            - class_1\n",
            "            - class_2\n",
            "\t\t\n",
            "    :Summary Statistics:\n",
            "    \n",
            "    ============================= ==== ===== ======= =====\n",
            "                                   Min   Max   Mean     SD\n",
            "    ============================= ==== ===== ======= =====\n",
            "    Alcohol:                      11.0  14.8    13.0   0.8\n",
            "<<26 more lines>>\n",
            "wine.\n",
            "\n",
            "Original Owners: \n",
            "\n",
            "Forina, M. et al, PARVUS - \n",
            "An Extendible Package for Data Exploration, Classification and Correlation. \n",
            "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
            "Via Brigata Salerno, 16147 Genoa, Italy.\n",
            "\n",
            "Citation:\n",
            "\n",
            "Lichman, M. (2013). UCI Machine Learning Repository\n",
            "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
            "School of Information and Computer Science. \n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  Comparison of Classifiers in High Dimensional Settings, \n",
            "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Technometrics). \n",
            "\n",
            "  The data was used with many others for comparing various \n",
            "  classifiers. The classes are separable, though only RDA \n",
            "  has achieved 100% correct classification. \n",
            "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
            "  (All results using the leave-one-out technique) \n",
            "\n",
            "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
            "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
            "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
            "  Mathematics and Statistics, James Cook University of North Queensland. \n",
            "  (Also submitted to Journal of Chemometrics).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(wine.DESCR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iInwRPgY63Rb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine.data, wine.target, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvcCFhr_63Rb",
        "outputId": "11d1fc0b-08ab-4196-dde3-4f1e2507d787"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>12.08</td>\n",
              "      <td>2.08</td>\n",
              "      <td>1.70</td>\n",
              "      <td>17.5</td>\n",
              "      <td>97.0</td>\n",
              "      <td>2.23</td>\n",
              "      <td>2.17</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.40</td>\n",
              "      <td>3.30</td>\n",
              "      <td>1.27</td>\n",
              "      <td>2.96</td>\n",
              "      <td>710.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>12.42</td>\n",
              "      <td>4.43</td>\n",
              "      <td>2.73</td>\n",
              "      <td>26.5</td>\n",
              "      <td>102.0</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.13</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.08</td>\n",
              "      <td>0.92</td>\n",
              "      <td>3.12</td>\n",
              "      <td>365.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>12.58</td>\n",
              "      <td>1.29</td>\n",
              "      <td>2.10</td>\n",
              "      <td>20.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>1.48</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.40</td>\n",
              "      <td>7.60</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.55</td>\n",
              "      <td>640.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>13.83</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2.60</td>\n",
              "      <td>17.2</td>\n",
              "      <td>94.0</td>\n",
              "      <td>2.45</td>\n",
              "      <td>2.99</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.60</td>\n",
              "      <td>1.24</td>\n",
              "      <td>3.37</td>\n",
              "      <td>1265.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "100    12.08        2.08  1.70               17.5       97.0           2.23   \n",
              "122    12.42        4.43  2.73               26.5      102.0           2.20   \n",
              "154    12.58        1.29  2.10               20.0      103.0           1.48   \n",
              "51     13.83        1.65  2.60               17.2       94.0           2.45   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "100        2.17                  0.26             1.40             3.30  1.27   \n",
              "122        2.13                  0.43             1.71             2.08  0.92   \n",
              "154        0.58                  0.53             1.40             7.60  0.58   \n",
              "51         2.99                  0.22             2.29             5.60  1.24   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "2                            3.17   1185.0  \n",
              "100                          2.96    710.0  \n",
              "122                          3.12    365.0  \n",
              "154                          1.55    640.0  \n",
              "51                           3.37   1265.0  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGiPxy2963Rb",
        "outputId": "84d201b1-23ae-41e7-a978-0547ec66f62a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2      0\n",
              "100    1\n",
              "122    1\n",
              "154    2\n",
              "51     0\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNIC19B63Rb"
      },
      "source": [
        "Let's start simple, with a linear SVM classifier. It will automatically use the One-vs-All (also called One-vs-the-Rest, OvR) strategy, so there's nothing special we need to do to handle multiple classes. Easy, right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQmkJQaB63Rb",
        "outputId": "fac56a29-507b-4cdd-e598-dc33c32ce533"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LinearSVC(random_state=42)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin_clf = LinearSVC(dual=True, random_state=42)\n",
        "lin_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnpNQooF63Rb"
      },
      "source": [
        "Oh no! It failed to converge. Can you guess why? Do you think we must just increase the number of training iterations? Let's see:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKfU1yud63Rb",
        "outputId": "08c35a7a-2741-4677-d298-5a785af769da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LinearSVC(max_iter=1000000, random_state=42)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin_clf = LinearSVC(max_iter=1_000_000, dual=True, random_state=42)\n",
        "lin_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_9tMaQK63Rb"
      },
      "source": [
        "Even with one million iterations, it still did not converge. There must be another problem.\n",
        "\n",
        "Let's still evaluate this model with `cross_val_score`, it will serve as a baseline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24fFeW_x63Rb",
        "outputId": "5725b0ee-95ca-4770-fb4d-ff3675145c03"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.90997150997151"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(lin_clf, X_train, y_train).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nhv0q4Z63Rc"
      },
      "source": [
        "Well 91% accuracy on this dataset is not great. So did you guess what the problem is?\n",
        "\n",
        "That's right, we forgot to scale the features! Always remember to scale the features when using SVMs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzCJXJrk63Rc",
        "outputId": "a8530f1d-333d-4e98-e334-958f43ffd170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('linearsvc', LinearSVC(random_state=42))])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin_clf = make_pipeline(StandardScaler(),\n",
        "                        LinearSVC(dual=True, random_state=42))\n",
        "lin_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eie4JV7f63Rc"
      },
      "source": [
        "Now it converges without any problem. Let's measure its performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRm784D763Rc",
        "outputId": "8d42a10e-45db-42f5-d19f-07a9bb0c4d1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9774928774928775"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(lin_clf, X_train, y_train).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzvFz9-163Rc"
      },
      "source": [
        "Nice! We get 97.7% accuracy, that's much better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpMqCya063Rc"
      },
      "source": [
        "Let's see if a kernelized SVM will do better. We will use a default `SVC` for now:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pizLTqmY63Rc",
        "outputId": "cae19e4c-3231-46d0-e27a-ce2162e9f0da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9698005698005698"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "svm_clf = make_pipeline(StandardScaler(), SVC(random_state=42))\n",
        "cross_val_score(svm_clf, X_train, y_train).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF3ace4u63Rc"
      },
      "source": [
        "That's not better, but perhaps we need to do a bit of hyperparameter tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVsEjpfA63Rc",
        "outputId": "4a758e30-43a5-4df2-e265-c63dd4cc516f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svc',\n",
              "                 SVC(C=9.925589984899778, gamma=0.011986281799901176,\n",
              "                     random_state=42))])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform, uniform\n",
        "\n",
        "param_distrib = {\n",
        "    \"svc__gamma\": loguniform(0.001, 0.1),\n",
        "    \"svc__C\": uniform(1, 10)\n",
        "}\n",
        "rnd_search_cv = RandomizedSearchCV(svm_clf, param_distrib, n_iter=100, cv=5,\n",
        "                                   random_state=42)\n",
        "rnd_search_cv.fit(X_train, y_train)\n",
        "rnd_search_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBeQyES363Rc",
        "outputId": "3acdcc33-1b63-4dbf-e3bf-9aa93f4ec029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9925925925925926"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_search_cv.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WappbRCd63Rc"
      },
      "source": [
        "Ah, this looks excellent! Let's select this model. Now we can test it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtjcH9Yr63Rc",
        "outputId": "38033ba7-6c92-4231-892b-adfc05e778df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9777777777777777"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_search_cv.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syZRY7zz63Rc"
      },
      "source": [
        "This tuned kernelized SVM performs better than the `LinearSVC` model, but we get a lower score on the test set than we measured using cross-validation. This is quite common: since we did so much hyperparameter tuning, we ended up slightly overfitting the cross-validation test sets. It's tempting to tweak the hyperparameters a bit more until we get a better result on the test set, but this would probably not help, as we would just start overfitting the test set. Anyway, this score is not bad at all, so let's stop here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68gY5dEc63Rc"
      },
      "source": [
        "## 11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3V2EntiM63Rc"
      },
      "source": [
        "_Exercise: Train and fine-tune an SVM regressor on the California housing dataset. You can use the original dataset rather than the tweaked version we used in Chapter 2. The original dataset can be fetched using `sklearn.datasets.fetch_california_housing()`. The targets represent hundreds of thousands of dollars. Since there are over 20,000 instances, SVMs can be slow, so for hyperparameter tuning you should use much less instances (e.g., 2,000), to test many more hyperparameter combinations. What is your best model's RMSE?_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFVC7b4s63Rc"
      },
      "source": [
        "Let's load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOd9DUCB63Rd"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di-jwv8J63Rd"
      },
      "source": [
        "Split it into a training set and a test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl-iDIUN63Rd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6apQyFOR63Rd"
      },
      "source": [
        "Don't forget to scale the data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqNvdwPV63Rd"
      },
      "source": [
        "Let's train a simple `LinearSVR` first:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDpq1jyi63Rd",
        "outputId": "119af4b6-0bf7-49bc-cabe-64e17ffedade"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ageron/miniconda3/envs/homl3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('linearsvr', LinearSVR(random_state=42))])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "lin_svr = make_pipeline(StandardScaler(), LinearSVR(dual=True, random_state=42))\n",
        "lin_svr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UsxnUIH63Rd"
      },
      "source": [
        "It did not converge, so let's increase `max_iter`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2pkaMJT63Rd",
        "outputId": "c5c429cd-1507-4c67-e659-b9917f4a5e21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('linearsvr', LinearSVR(max_iter=5000, random_state=42))])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lin_svr = make_pipeline(StandardScaler(),\n",
        "                        LinearSVR(max_iter=5000, dual=True, random_state=42))\n",
        "lin_svr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdHl26My63Rd"
      },
      "source": [
        "Let's see how it performs on the training set:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKxEEBQf63Rd"
      },
      "source": [
        "**Warning**: In recent versions of Scikit-Learn, you must use `root_mean_squared_error()` to compute the RMSE, instead of `mean_squared_error(labels, predictions, squared=False)`. The following `try`/`except` block tries to import `root_mean_squared_error`, and if it fails it just defines it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfE-q0Mq63Rd"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from sklearn.metrics import root_mean_squared_error\n",
        "except ImportError:\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    def root_mean_squared_error(labels, predictions):\n",
        "        return mean_squared_error(labels, predictions, squared=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "age1P_NO63Rd",
        "outputId": "7f49ba63-9e38-458e-fa92-338df21e07a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9595484665813285"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = lin_svr.predict(X_train)\n",
        "mse = root_mean_squared_error(y_train, y_pred)\n",
        "mse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMsOTO-u63Rd"
      },
      "source": [
        "Let's look at the RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMspIq8_63Rd",
        "outputId": "564e440a-25aa-41ed-d5a3-813e8be3f438"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.979565447829459"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.sqrt(mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7eGnSJx63Rd"
      },
      "source": [
        "In this dataset, the targets represent hundreds of thousands of dollars. The RMSE gives a rough idea of the kind of error you should expect (with a higher weight for large errors): so with this model we can expect errors close to $98,000! Not great. Let's see if we can do better with an RBF Kernel. We will use randomized search with cross validation to find the appropriate hyperparameter values for `C` and `gamma`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuw8pASD63Rd",
        "outputId": "dbf0ba47-6085-428f-c1d3-ee74d7549b0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=Pipeline(steps=[('standardscaler',\n",
              "                                              StandardScaler()),\n",
              "                                             ('svr', SVR())]),\n",
              "                   n_iter=100,\n",
              "                   param_distributions={'svr__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff030704ee0>,\n",
              "                                        'svr__gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff030704fd0>},\n",
              "                   random_state=42)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import loguniform, uniform\n",
        "\n",
        "svm_reg = make_pipeline(StandardScaler(), SVR())\n",
        "\n",
        "param_distrib = {\n",
        "    \"svr__gamma\": loguniform(0.001, 0.1),\n",
        "    \"svr__C\": uniform(1, 10)\n",
        "}\n",
        "rnd_search_cv = RandomizedSearchCV(svm_reg, param_distrib,\n",
        "                                   n_iter=100, cv=3, random_state=42)\n",
        "rnd_search_cv.fit(X_train[:2000], y_train[:2000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQx-WSBi63Rd",
        "outputId": "019a6f57-2a8f-4a9f-c05e-d2dd07cfba73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('svr', SVR(C=4.63629602379294, gamma=0.08781408196485974))])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd_search_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne0RvjuH63Rd",
        "outputId": "dc55464a-5e57-469b-ba07-c2cd27a9e819"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.58835648, 0.57468589, 0.58085278, 0.57109886, 0.59853029])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "-cross_val_score(rnd_search_cv.best_estimator_, X_train, y_train,\n",
        "                 scoring=\"neg_root_mean_squared_error\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EDez3xg63Re"
      },
      "source": [
        "Looks much better than the linear model. Let's select this model and evaluate it on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnN-xGis63Re",
        "outputId": "f4df6f51-dd29-449d-ae20-0a431c49cd92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5854732265172222"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = rnd_search_cv.best_estimator_.predict(X_test)\n",
        "rmse = root_mean_squared_error(y_test, y_pred)\n",
        "rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDbHbLR363Re"
      },
      "source": [
        "So SVMs worked very well on the Wine dataset, but not so much on the California Housing dataset. In Chapter 2, we found that Random Forests worked better for that dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUauzbgO63Re"
      },
      "source": [
        "And that's all for today!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yogIhSHj63Re"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}